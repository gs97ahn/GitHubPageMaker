<!DOCTYPE html>
<html>

<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Big Data - Text Mining</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Web Font Setting -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Prompt&display=swap">
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>
        .hljs {
            background: none;
        }
    </style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->

    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="Computer Science & Engineering" />
    <link rel="shortcut icon" href="/assets/built/images/favicon.png" type="image/png" />
    <link rel="canonical" href="/Big_Data-Text_Mining" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="nogamsung" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Big Data - Text Mining" />
    <meta property="og:description" content="What is “Text Mining”? “Text mining, also referred to as text data mining, roughly equivalent to text analytics, refers to the process of deriving high-quality information from text.” - wikipedia “Another way to view text data mining is as a process fo exploratory data analysis that lead to heretofore unknown" />
    <meta property="og:url" content="/Big_Data-Text_Mining" />
    <meta property="og:image" content="/assets/built/images/big-data-logo.jpeg" />
    <meta property="article:publisher" content="https://www.facebook.com/" />
    <meta property="article:author" content="https://www.facebook.com/" />
    <meta property="article:published_time" content="2022-11-21T22:30:00+09:00" />
    <meta property="article:modified_time" content="2022-11-21T22:30:00+09:00" />
    <meta property="article:tag" content="Comsci" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Big Data - Text Mining" />
    <meta name="twitter:description" content="What is “Text Mining”? “Text mining, also referred to as text data mining, roughly equivalent to text analytics, refers to the process of deriving high-quality information from text.” - wikipedia “Another way to view text data mining is as a process fo exploratory data analysis that lead to heretofore unknown" />
    <meta name="twitter:url" content="/" />
    <meta name="twitter:image" content="/assets/built/images/big-data-logo.jpeg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="nogamsung" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Comsci" />
    <meta name="twitter:site" content="@" />
    <meta name="twitter:creator" content="@" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "nogamsung",
        "logo": "/"
    },
    "url": "/Big_Data-Text_Mining",
    "image": {
        "@type": "ImageObject",
        "url": "/assets/built/images/big-data-logo.jpeg",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "/Big_Data-Text_Mining"
    },
    "description": "What is “Text Mining”? “Text mining, also referred to as text data mining, roughly equivalent to text analytics, refers to the process of deriving high-quality information from text.” - wikipedia “Another way to view text data mining is as a process fo exploratory data analysis that lead to heretofore unknown"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Big Data - Text Mining" href="/feed.xml" />


</head>

<body
    class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
        
        <a class="site-nav-logo" href="/">nogamsung</a>
        
        
        
        <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-frontend" role="menuitem"><a href="/tag/frontend/">Frontend</a></li>
    <li class="nav-backend" role="menuitem"><a href="/tag/backend/">Backend</a></li>
    <li class="nav-backend" role="menuitem"><a href="/tag/devops/">DevOps</a></li>
    <li class="nav-ai" role="menuitem"><a href="/tag/ai/">AI</a></li>
    <li class="nav-backend" role="menuitem"><a href="/tag/comsci/">ComSci</a></li>
    <li class="nav-etc" role="menuitem"><a href="/tag/etc/">ETC</a></li>
    <li class="nav-archive" role="menuitem">
        <a href="/archive.html">All Posts</a>
    </li>
    <li class="nav-archive" role="menuitem">
        <a href="/author_archive.html">Tag</a>
    </li>
</ul>
        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
        <a class="subscribe-button" href="#subscribe">Search</a>
        
    </div>
</nav>
    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-comsci post tag-comsci ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="21 November 2022">21 November 2022</time>
                    
                    <span class="date-divider">/</span>
                    
                    
                    <a href='/tag/comsci/'>COMSCI</a>
                    
                    
                    
                </section>
                <h1 class="post-full-title">Big Data - Text Mining</h1>
            </header>

            
            <figure class="post-full-image" style="background-image: url(/assets/built/images/big-data-logo.jpeg)">
            </figure>
            

            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <h3 id="what-is-text-mining">What is “Text Mining”?</h3>
<ul>
  <li>“Text mining, also referred to as <strong>text data mining</strong>, roughly equivalent to text analytics, refers to the process of
deriving high-quality information from text.” - wikipedia</li>
  <li>“Another way to view text data mining is as a process fo <strong>exploratory</strong> data analysis that lead to <strong>heretofore
unknown</strong> information, or to answers for questions for which the answer is not currently known.” - Hearst, 1999</li>
</ul>

<h3 id="text-mining-around-us">Text mining around us</h3>
<ul>
  <li>Sentiment analysis</li>
</ul>

<p><img src="assets/screenshots/2022/11/21/1.jpeg" alt="" /></p>

<ul>
  <li>Document summarization</li>
</ul>

<p><img src="assets/screenshots/2022/11/21/2.jpeg" alt="" /></p>

<p><img src="assets/screenshots/2022/11/21/3.jpeg" alt="" /></p>

<ul>
  <li>News recommendation</li>
</ul>

<p><img src="assets/screenshots/2022/11/21/4.jpeg" alt="" /></p>

<ul>
  <li>Text analytics in financial services</li>
</ul>

<p><img src="assets/screenshots/2022/11/21/5.jpeg" alt="" /></p>

<ul>
  <li>Text analytics in healthcare</li>
</ul>

<p><img src="assets/screenshots/2022/11/21/6.jpeg" alt="" /></p>

<h3 id="how-to-perform-text-mining">How to perform text mining?</h3>
<ul>
  <li>As computer scientists, we view it as
    <ul>
      <li>Text Mining = <strong>Data Mining</strong> + <strong>Text Data</strong>
        <ul>
          <li>Data Mining
            <ul>
              <li>Information retrieval</li>
              <li>Natural language processing</li>
              <li>Applied machine learning</li>
            </ul>
          </li>
          <li>Text Data
            <ul>
              <li>Scientific literature</li>
              <li>Email, Tweets, News articles</li>
              <li>Software documentations</li>
              <li>Blogs, Web pages</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="text-mining-vs-nl-ir-dm">Text mining vs. NL, IR, DM…</h3>
<ul>
  <li>How does it relate to data mining in general?</li>
  <li>How does it relate to computations linguistics?</li>
  <li>How does it relate to information retrieval?</li>
</ul>

<p><img src="assets/screenshots/2022/11/21/7.jpeg" alt="" /></p>

<h3 id="text-mining-in-general">Text mining in general</h3>

<p><img src="assets/screenshots/2022/11/21/8.jpeg" alt="" /></p>

<h3 id="challenges-in-text-mining">Challenges in text mining</h3>
<ul>
  <li>Data collections is “free text”
    <ul>
      <li>Data is not well-organized
        <ul>
          <li>Semi-structured or unstructured</li>
        </ul>
      </li>
      <li>Natural language text contains ambiguities on many levels
        <ul>
          <li>Lexical, syntactic, semantic, and pragmatic</li>
        </ul>
      </li>
      <li>Learning techniques for processing text typically need annotated traning examples
        <ul>
          <li>Expensive to acquire at scale</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>What to mine?</li>
  <li>Huge in size
    <ul>
      <li>Google processes 5.13 B queries/day (2013)</li>
      <li>Twitter receives 340 M tweets/day (2012)</li>
      <li>Facebook has 2.5 PB of user data + 15 TB/day (4/2009)</li>
    </ul>
  </li>
  <li>80% data is unstructured (IBM, 2010)</li>
</ul>

<h3 id="scalability-is-crucial">Scalability is crucial</h3>
<ul>
  <li>Large scale text processing techniques
    <ul>
      <li>MapReduce framework</li>
    </ul>
  </li>
</ul>

<p><img src="assets/screenshots/2022/11/21/9.jpeg" alt="" /></p>

<h3 id="state-of-the-art-solutions">State-of-the-art solutions</h3>
<ul>
  <li>Apache Spark
    <ul>
      <li>In-memory MapReduce
        <ul>
          <li>Specialized for machine learning algorithms</li>
        </ul>
      </li>
      <li>Speed
        <ul>
          <li>100x faster than Hadoop MapReduce in memory or 10x faster on disk.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="assets/screenshots/2022/11/21/10.jpeg" alt="" /></p>

<ul>
  <li>In-memory MapReduce
    <ul>
      <li>Specialized for machine learning algorithms</li>
    </ul>
  </li>
  <li>Generality
    <ul>
      <li>Combine SQL, streaming, and complex analytics</li>
    </ul>
  </li>
</ul>

<p><img src="assets/screenshots/2022/11/21/11.jpeg" alt="" /></p>

<h2 id="document-representation">Document Representation</h2>
<h3 id="how-to-represent-a-document">How to represent a document</h3>
<ul>
  <li>Represent by a string?
    <ul>
      <li>No semantic meaning</li>
    </ul>
  </li>
  <li>Represent by a list of sentences?
    <ul>
      <li>Sentence is just like a short document (recursive definition)</li>
    </ul>
  </li>
</ul>

<h3 id="vector-space-vs-model">Vector Space (VS) model</h3>
<ul>
  <li>Represent documents by concept vectors
    <ul>
      <li>Each concept defines one dimension</li>
      <li><em>k</em> concepts define a high-dimensional space</li>
      <li>Element of vector corresponds to concept weight</li>
    </ul>
  </li>
  <li>Distance between the vectors in this concept space
    <ul>
      <li>Relationship among documents</li>
    </ul>
  </li>
</ul>

<h3 id="an-illustration-of-vs-model">An illustration of VS model</h3>
<ul>
  <li>All documents are projected into this concept space</li>
</ul>

<p><img src="assets/screenshots/2022/11/21/12.jpeg" alt="" /></p>

<h3 id="what-the-vs-model-doesnt-say">What the VS model doesn’t say</h3>
<ul>
  <li>How to define/select the “basic concept”
    <ul>
      <li>Concepts are assumed to be orthogonal</li>
    </ul>
  </li>
  <li>How to assign weights
    <ul>
      <li>Weights indicate how well the concept characterizes the document</li>
    </ul>
  </li>
  <li>How to define the distance metric</li>
</ul>

<h3 id="what-is-a-good-basic-concept">What is a good “Basic Concept”?</h3>
<ul>
  <li>Orthogonal
    <ul>
      <li>Linearly independent basis vectors
        <ul>
          <li>“Non-overlapping” in meaning</li>
        </ul>
      </li>
      <li>No ambiguity</li>
    </ul>
  </li>
  <li>Weights should be assigned automatically and accurately</li>
  <li>Existing solutions
    <ul>
      <li>Terms or N-grams, a.k.a., Bag-of-Words</li>
      <li>Topics</li>
    </ul>
  </li>
</ul>

<h2 id="document-representation-bag-of-words">Document Representation: Bag-of-Words</h2>
<h3 id="bag-of-words-representation">Bag-of-Words representation</h3>
<ul>
  <li>Term as the basis for vector space
    <ul>
      <li>Doc1: Text mining is to identify useful information.</li>
      <li>Doc2: Useful information is mined from text.</li>
      <li>Doc3: Apple is delicious.</li>
    </ul>
  </li>
</ul>

<p><img src="assets/screenshots/2022/11/21/13.jpeg" alt="" /></p>

<h3 id="tokenization">Tokenization</h3>
<ul>
  <li>Break a stream of text into meaningful units
    <ul>
      <li>Tokens: words, phrases, symbols
        <ul>
          <li>Input: It’s not straight-forward to perform so-called “tokenization”.</li>
          <li>Output(1): “‘It’s’, ‘not’, ‘straight-forward”, ‘to’, ‘perform’, ‘so-called’, ‘tokenization’”</li>
          <li>Output(2): “‘It’, ‘’s’, ‘not’, ‘straight’, ‘-‘, ‘forward’, ‘to’, ‘perform’, ‘so’, ‘-‘, ‘called’, ‘tokenization’”</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Definition depends on language, corpus, or even context</li>
  <li>Solutions
    <ul>
      <li>Regular expressions
        <ul>
          <li>[\w]+: so-called -&gt; ‘so’, ‘called’</li>
          <li>[\S]+: It’s -&gt; ‘It’s’ instead of ‘It’, ‘’s’</li>
        </ul>
      </li>
      <li>Statistical methods
        <ul>
          <li>Explore rich features to decide where the boundary of a word is
            <ul>
              <li>Apache OpenNLP</li>
              <li>Standford NLP Parser</li>
            </ul>
          </li>
          <li>Online Demo
            <ul>
              <li>Standford</li>
              <li>UIUC</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="bag-of-words-representation-1">Bag-of-Words representation</h3>

<p><img src="assets/screenshots/2022/11/21/14.jpeg" alt="" /></p>

<ul>
  <li>Assumption
    <ul>
      <li>Words are independent from each other</li>
    </ul>
  </li>
  <li>Pros
    <ul>
      <li>Simple</li>
    </ul>
  </li>
  <li>Cons
    <ul>
      <li>Basis vectors are clearly not linearly independent!</li>
      <li>Grammar and order are missing</li>
    </ul>
  </li>
  <li>The ost frequently used document representation
    <ul>
      <li>Image, speech, gene sequence</li>
    </ul>
  </li>
</ul>

<h3 id="bag-of-words-with-n-grams">Bag-of-Words with N-grams</h3>
<ul>
  <li>N-grams: a contiguous sequence of N tokens from a given piece of test
    <ul>
      <li>E.g., ‘Text mining is to identify useful information’</li>
      <li>Bigrams: ‘text_mining’, ‘mining_is’, ‘is_to’, ‘to_identify’, ‘identify_useful’, ‘useful_information’, ‘information_’</li>
    </ul>
  </li>
  <li>Pros: capture local dependency and order</li>
  <li>Cons: a pure statistical view, increase the vocabulary size O(V<sup>N</sup>)</li>
</ul>

<h3 id="automatic-document-representation">Automatic document representation</h3>
<ul>
  <li>Represent a document with all the occurring words
    <ul>
      <li>Pros
        <ul>
          <li>Preserve all information in the text (hopefully)</li>
          <li>Fully automatic</li>
        </ul>
      </li>
      <li>Cons
        <ul>
          <li>Vocabulary gap: cars versus car, talk versus talking</li>
          <li>Large storage: N-grams needs O(V<sup>N</sup>)</li>
        </ul>
      </li>
      <li>Solution
        <ul>
          <li>Construct controlled vocabulary</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="a-statistical-property-of-language">A statistical property of language</h3>
<ul>
  <li>Zipf’s law
    <ul>
      <li>Frequency of any word is inversely proportional to tis rank in the frequency table</li>
      <li>Formally</li>
    </ul>
  </li>
</ul>

<p><img src="https://latex.codecogs.com/svg.image?f(k;s,N)=\frac{1/k^s}{\sum_{n=1}^{N}1/n^s}v" alt="" /></p>

<p>where <em>k</em> is rank of word; <em>N</em> is the vocabulary size; <em>s</em> is language-specific parameter</p>

<ul>
  <li>Simply</li>
</ul>

<p><img src="https://latex.codecogs.com/svg.image?f(k;s,N)\propto&space;1/k^s" alt="" /></p>

<p><img src="assets/screenshots/2022/11/21/15.jpeg" alt="" /></p>

<h3 id="zipfs-law-tells-us">Zipf’s law tells us</h3>
<ul>
  <li>Head words take large portion of occurrences, but they are semantically meaningless
    <ul>
      <li>E.g., the, a, an, we, do, to</li>
    </ul>
  </li>
  <li>Trail words take major portion of vocabulary, but they rarely occur in documents
    <ul>
      <li>E.g., sesquipedalianism</li>
    </ul>
  </li>
  <li>The rest is most representative
    <ul>
      <li>To be included in the controlled vocabulary</li>
    </ul>
  </li>
</ul>

<h3 id="automatic-document-representation-1">Automatic document representation</h3>

<p><img src="assets/screenshots/2022/11/21/16.jpeg" alt="" /></p>

<h3 id="stopwords">Stopwords</h3>
<ul>
  <li>Useless words for document analaysis
    <ul>
      <li>Not all words are informative</li>
      <li>Remove such words to reduce vocabulary size</li>
      <li>No universal definition</li>
      <li>Risk: break the original meaning and structure of text
        <ul>
          <li>E.g., this is not a good option -&gt; option to be or not to be -&gt; null</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="normalization">Normalization</h3>
<ul>
  <li>Convert different forms of a word to a normalized form in the vocabulary
    <ul>
      <li>U.S.A -&gt; USA, ST.Louis -&gt; Saint Louis</li>
    </ul>
  </li>
  <li>Solution
    <ul>
      <li>Rule-based
        <ul>
          <li>Delete periods and hyphens</li>
          <li>All in lower cases</li>
        </ul>
      </li>
      <li>Dictionary-based
        <ul>
          <li>Construct equivalent calss
            <ul>
              <li>Car -&gt; “automobile, vehicle”</li>
              <li>Mobile phone -&gt; “cellphone”</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="stemming">Stemming</h3>
<ul>
  <li>Reduce inflected or derived words to their root form
    <ul>
      <li>Plurals, adverbs, inflected word forms
        <ul>
          <li>E.g., ladies -&gt; lady, referring -&gt; refer, forgotten -&gt; forget</li>
        </ul>
      </li>
      <li>Bridge the vocabulary gap</li>
      <li>Solutions (for English)
        <ul>
          <li>Porter stemmer: patterns of vowel-consonant sequence</li>
          <li>Krovetz stemmer: morphological rules</li>
        </ul>
      </li>
      <li>Risk: lose precise meaning of the word
        <ul>
          <li>E.g., lay -&gt; lie (a false statement? or be in a horizontal position?)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="constructing-a-vsm-representation">Constructing a VSM representation</h3>

<p><img src="assets/screenshots/2022/11/21/17.jpeg" alt="" /></p>

<h3 id="how-to-assign-weights">How to assign weights?</h3>
<ul>
  <li>Important!</li>
  <li>Why?
    <ul>
      <li>Corpus-wise: some terms carry more information about the document content</li>
      <li>Document-wise: not all terms are equally important</li>
    </ul>
  </li>
  <li>How?
    <ul>
      <li>Two basic heuristics
        <ul>
          <li>TF (Term Frequency) = Within-doc-frequency</li>
          <li>IDF (Inverse Document Frequency)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="term-frequency">Term frequency</h3>
<ul>
  <li>Idea: a term is more important if it occurs more frequently in a document</li>
  <li>TF Formulas
    <ul>
      <li>Let c(t,d) be the frequency count of term t in doc d</li>
      <li>Raw TF: tf(t,d) = c(t,d)</li>
    </ul>
  </li>
</ul>

<p>Which two documents are more similar to each other?</p>
<ol>
  <li>‘good weather’, 10</li>
  <li>‘good weather’, 2</li>
  <li>‘good weather’, 3</li>
</ol>

<h3 id="tf-normalization">TF normalization</h3>
<ul>
  <li>Two views of document length
    <ul>
      <li>A doc is long because it is verbose</li>
      <li>A doc is long because it has more content</li>
    </ul>
  </li>
  <li>Raw TF is inaccurate
    <ul>
      <li>Document length variation</li>
      <li>“Repeated occurrences” are less informative than the “first occurrence”</li>
      <li>Information about semantic does not increase proportionally with number of term occurrence</li>
    </ul>
  </li>
  <li>Generally penalize long document, but avoid over-penalizing
    <ul>
      <li>Pivoted length normalization</li>
    </ul>
  </li>
  <li>Maximum TF scaling
    <ul>
      <li>Normalize by the most frequent word in this doc</li>
    </ul>
  </li>
</ul>

<p><img src="https://latex.codecogs.com/svg.image?tf(t,d)=\alpha&space;&plus;(a-\alpha)\frac{c(t,d)}{max_tc(t,d)'},&space;if&space;c(t,d)&gt;0" alt="" /></p>

<p><img src="assets/screenshots/2022/11/21/18.jpeg" alt="" /></p>

<ul>
  <li>Sub-linear TF scaling</li>
</ul>

<p><img src="assets/screenshots/2022/11/21/19.jpeg" alt="" /></p>

<p><img src="assets/screenshots/2022/11/21/20.jpeg" alt="" /></p>

<ul>
  <li>Idea: a term is more discriminative if it occurs only in fewer documents</li>
</ul>

<p><img src="assets/screenshots/2022/11/21/21.jpeg" alt="" /></p>

<h3 id="inverse-document-frequency">Inverse document frequency</h3>
<ul>
  <li>Solution
    <ul>
      <li>Assign higher weights to rare terms</li>
      <li>Formula</li>
    </ul>
  </li>
</ul>

<p><img src="assets/screenshots/2022/11/21/22.jpeg" alt="" /></p>

<ul>
  <li>A corpus-specific property
    <ul>
      <li>Independent of a single document</li>
    </ul>
  </li>
</ul>

<h3 id="what-document-frequency">What document frequency</h3>
<ul>
  <li>How about total term frequency?</li>
</ul>

<p><img src="https://latex.codecogs.com/svg.image?ttf(t)=\sum_{d}c(t,d)" alt="" /></p>

<p><img src="assets/screenshots/2022/11/21/23.jpeg" alt="" /></p>

<p>Cannot recognize words frequently occurring in a subset of documents</p>

<h3 id="tf-idf-weighting">TF-IDF weighting</h3>
<ul>
  <li>Combining TF and IDF
    <ul>
      <li>Common in doc -&gt; high tf -&gt; high weight</li>
      <li>Rare in collection -&gt; high idf -&gt; high weight</li>
    </ul>
  </li>
</ul>

<p><img src="https://latex.codecogs.com/svg.image?w(t,d)=TF(t,d)\times&space;IDF(t)" alt="" /></p>

<ul>
  <li>Most well-known document representation schema in IR (G Salton et al. 1983)</li>
</ul>

<h3 id="how-to-define-a-good-similarity-metric">How to define a good similarity metric?</h3>
<ul>
  <li>Euclidean distance?
    <ul>
      <li>Longer documents will be penalized by the extra words</li>
      <li>We care more about how these two vectors are overlapped</li>
    </ul>
  </li>
</ul>

<p><img src="https://latex.codecogs.com/svg.image?dist(d_i,d_j)=\sqrt{\sum_{t\in&space;V}[tf(t,d_i)idf(t)-tf(t,d_j)idf(t)]^2}" alt="" /></p>

<p><img src="assets/screenshots/2022/11/21/24.jpeg" alt="" /></p>

<h3 id="from-distance-to-angle">From distance to angle</h3>
<ul>
  <li>Angle: how vectors are overlapped
    <ul>
      <li>Cosine similarity - projection of one vector onto another</li>
    </ul>
  </li>
</ul>

<p><img src="assets/screenshots/2022/11/21/25.jpeg" alt="" /></p>

<h3 id="cosine-similarity">Cosine similarity</h3>
<ul>
  <li>Angle between two vectors</li>
</ul>

<table>
  <tbody>
    <tr>
      <td>![](https://latex.codecogs.com/svg.image?cosine(d_i,d_j)=\frac{V_{d_i}^TV_{d_j}}{</td>
      <td>d_{d_i}</td>
      <td>_2\times&amp;space;</td>
      <td>v_{d_j}</td>
      <td>}_2)</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>Documents are normalized by length</li>
</ul>

<p><img src="assets/screenshots/2022/11/21/26.jpeg" alt="" /></p>

<h3 id="advantage-and-disadvantage-of-vs-model">Advantage and Disadvantage of VS model</h3>
<p>|                Pros                |             Cons              |
|:———————————-:|:—————————–:|
|       Empirically effective        |    Assume term idependence    |
|             Intuitive              | Lack of “predictive adequacy” |
|         Easy to implement          |   Lots of parameter tuning    |
|   Well-studied/mostly evaluated    |                               |
|          The Smart system          |                               |
| Warning: maning variants of TF-IDF |                               |</p>

<h2 id="reference">Reference</h2>
<ul>
  <li><a href="http://www.mmds.org/" target="_blank">Mining of Massive Datasets by Jure Leskovec, Anand Rajaraman, Jeff Ullman</a></li>
  <li>Introduction to Big Data Lecture by <a href="https://www.inu.ac.kr/user/indexSub.do?codyMenuSeq=2236524&amp;siteId=isis&amp;dum=dum&amp;command=empDetail&amp;empNum=20201168&amp;empSearchTab=01&amp;deptCode=&amp;siteId=isis" target="_blank">Daejin Choi</a> in <a href="https://www.inu.ac.kr/" target="_blank">Incheon National University</a></li>
</ul>

                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
            <!---
            
                <section class="subscribe-form">
                    <h3 class="subscribe-form-title">Subscribe to nogamsung</h3>
                    <p>Get the latest posts delivered right to your inbox</p>
                    <span id="searchform" method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm" />
    <input class="location" type="hidden" name="location" />
    <input class="referrer" type="hidden" name="referrer" />

    <div class="form-group">
        <input class="subscribe-email" onkeyup="myFunc()" id="searchtext" type="text" name="searchtext"
            placeholder="Search..." />
    </div>
    <script type="text/javascript">
        function myFunc() {
            if (event.keyCode == 13) {
                var url = encodeURIComponent($("#searchtext").val());
                location.href = "/search.html?query=" + url;
            }
        }
    </script>
</span>
                </section>
            
            -->

            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                
                <section class="author-card">
                    
                    <img class="author-profile-image" src="/assets/built/images/author-logo.jpeg"
                        alt="gs97ahn" />
                    
                    <section class="author-card-content">
                        <h4 class="author-card-name"><a href="/author/gs97ahn">nogamsung</a></h4>
                        
                        <p><a href="gs97ahn.github.io/about/">Geomseong Ahn</a></p>
                        
                    </section>
                </section>
                <div class="post-full-footer-right">
                    <a class="author-card-button" href="/author/gs97ahn">Read More</a>
                </div>
                
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            
            <section class="post-full-comments">
                <div id="disqus_thread"></div>
                <script>
                    var disqus_config = function () {
                        var this_page_url = '/Big_Data-Text_Mining';
                        var this_page_identifier = '/Big_Data-Text_Mining';
                        var this_page_title = 'Big Data - Text Mining';
                    };
                    (function () {
                        var d = document, s = d.createElement('script');
                        s.src = 'https://geomseongahn.disqus.com/embed.js';
                        s.setAttribute('data-timestamp', +new Date());
                        (d.head || d.body).appendChild(s);
                    })();
                </script>
            </section>
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
            
            
            
            
            <article class="read-next-card" 
                style="background-image: url(/assets/built/images/blog-cover.jpg)" >
                <header class="read-next-card-header">
                    <small class="read-next-card-header-sitetitle">&mdash; nogamsung &mdash;</small>
                    
                    <h3 class="read-next-card-header-title"><a href="/tag/comsci/">Comsci</a></h3>
                    
                </header>
                <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                <div class="read-next-card-content">
                    <ul>
                        
                        
                        
                        
                        
                         <li><a href="/Big_Data-Text_Mining_(LSA)_Visualization">Big Data - Text Mining (LSA) Visualization</a></li>
                            
                            
                            
                            
                        
                        
                        
                         <li><a href="/Computer_Network-Overview_of_Network_Layer">Computer Network - Overview of Network Layer</a></li>
                            
                            
                            
                            
                        
                        
                            
                            
                        
                        
                        
                         <li><a href="/Computer_Network-TCP_Congestion_Control">Computer Network - TCP Congestion Control</a></li>
                            
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                        
                        
                        
                            
                            
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                        
                            
                    </ul>
                </div>
                <footer class="read-next-card-footer">
                    <a href="/tag/comsci/">
                        
                        See all 44 posts →
                        
                    </a>
                </footer>
            </article>
            
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
            

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Computer_Network-Overview_of_Network_Layer">
                <div class="post-card-image" style="background-image: url(/assets/built/images/computer-network-logo.jpeg)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Computer_Network-Overview_of_Network_Layer">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Comsci</span>
                            
                        
                    

                    <h2 class="post-card-title">Computer Network - Overview of Network Layer</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>1️⃣ Forwarding and Routing: The Data and Control Planes

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                        
                        <img class="author-profile-image" src="/assets/built/images/author-logo.jpeg" alt="nogamsung" />
                        
                        <span class="post-card-author">
                            <a href="/author/gs97ahn/">nogamsung</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      1 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
            

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Computer_Network-TCP_Congestion_Control">
                <div class="post-card-image" style="background-image: url(/assets/built/images/computer-network-logo.jpeg)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Computer_Network-TCP_Congestion_Control">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Comsci</span>
                            
                        
                    

                    <h2 class="post-card-title">Computer Network - TCP Congestion Control</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>1️⃣ Classic TCP Congestion Control

  Congestion window: Denoted cwnd, imposes a constraint on the rate at which a TCP sender can send traffic into
the network.


</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                        
                        <img class="author-profile-image" src="/assets/built/images/author-logo.jpeg" alt="nogamsung" />
                        
                        <span class="post-card-author">
                            <a href="/author/gs97ahn/">nogamsung</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      2 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="/">
            
            <span>nogamsung</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">Big Data - Text Mining</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw"
            href="https://twitter.com/share?text=Big+Data+-+Text+Mining&amp;url=https://gs97ahn.github.io/Big_Data-Text_Mining"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb"
            href="https://www.facebook.com/sharer/sharer.php?u=https://gs97ahn.github.io/Big_Data-Text_Mining"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>

<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->

        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="/">nogamsung</a> &copy; 2022</section>
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a>
                </section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
    <div id="subscribe" class="subscribe-overlay">
        <a class="subscribe-overlay-close" href="#"></a>
        <div class="subscribe-overlay-content">
            
            <h1 class="subscribe-overlay-title">Search nogamsung</h1>
            <span id="searchform" method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm" />
    <input class="location" type="hidden" name="location" />
    <input class="referrer" type="hidden" name="referrer" />

    <div class="form-group">
        <input class="subscribe-email" onkeyup="myFunc()" id="searchtext" type="text" name="searchtext"
            placeholder="Search..." />
    </div>
    <script type="text/javascript">
        function myFunc() {
            if (event.keyCode == 13) {
                var url = encodeURIComponent($("#searchtext").val());
                location.href = "/search.html?query=" + url;
            }
        }
    </script>
</span>
        </div>
    </div>
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function () {
            $('pre code').each(function (i, block) {
                hljs.highlightBlock(block);
            });
        });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous">
        </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-227528384-1', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
    <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>

</html>